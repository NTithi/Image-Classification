{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyMggba9Fc+z7lod2oC5LN7L"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"PIZGA2HumY4R"},"outputs":[],"source":["#Step 1: Set Up the Environment\n","'''This installs TensorFlow, which is the main library we'll use for building,\n","training, and running our image classification model.\n","'''\n","!pip install tensorflow"]},{"cell_type":"code","source":["#Step 2: Import Libraries\n","'''tensorflow: The core library used for deep learning tasks.\n","layers, models: For building neural network layers and models.\n","MobileNetV2: A pre-trained model we'll use as a base.\n","ImageDataGenerator: To augment and preprocess the images.\n","to_categorical: Converts class labels to a one-hot encoding format.\n","'''\n","\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.applications import MobileNetV2\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.utils import to_categorical\n","import numpy as np"],"metadata":{"id":"n8PzkoDZui6I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Step 3: Load and Preprocess the CIFAR-10 Dataset\n","'''\n","Loading the dataset: The CIFAR-10 dataset is available directly through Keras,\n","                    containing 60,000 32x32 color images in 10 different classes\n","                    (e.g., airplanes, cars, birds).\n","Normalization: We divide by 255.0 to scale pixel values between 0 and 1.\n","                This helps the model train faster and perform better.\n","One-hot encoding: Converts the labels into a format suitable for multi-class classification.\n","                For instance, label 3 will become [0, 0, 0, 1, 0, 0, 0, 0, 0, 0].\n","'''\n","# Load the dataset\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n","\n","# Normalize the pixel values to be between 0 and 1\n","x_train, x_test = x_train / 255.0, x_test / 255.0\n","\n","# Convert labels to one-hot encoding\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","\n","# Check the shapes of data\n","print(f\"x_train shape: {x_train.shape}\")\n","print(f\"x_test shape: {x_test.shape}\")\n","print(f\"y_train shape: {y_train.shape}\")\n","print(f\"y_test shape: {y_test.shape}\")\n"],"metadata":{"id":"Qbz9CP9Qui9J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Step 4: Data Augmentation\n","'''\n","Why use data augmentation?:\n"," It artificially expands the dataset by making slight modifications\n"," (e.g., rotating, shifting, flipping). This helps prevent overfitting,\n","  making the model more robust.\n","Parameters:\n","rotation_range: Rotates the images by up to 15 degrees.\n","width_shift_range and height_shift_range: Shifts the image horizontally and vertically\n"," by a fraction of the width/height.\n","horizontal_flip: Randomly flips images horizontally.\n","'''\n","\n","datagen = ImageDataGenerator(\n","    rotation_range=15,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    horizontal_flip=True\n",")\n","\n","datagen.fit(x_train)"],"metadata":{"id":"jtUMc4DTui_4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Step 5: Set Up the Pre-trained Model\n","'''\n","Pre-trained models:\n","  Models like MobileNetV2 are already trained on a large dataset (ImageNet).\n"," By using them as a \"base,\" you can leverage their feature extraction capabilities\n"," and speed up training.\n","Why freeze the base model (trainable = False)?\n","Since the pre-trained model already knows general image features,\n","we can save training time by only training the new layers we've added.\n","Adding custom layers:\n","GlobalAveragePooling2D: Reduces the dimensions of the feature maps,\n","                       keeping the most essential features.\n","Dense layers: Adds fully connected layers for classification.\n","              The last layer has 10 neurons (one for each CIFAR-10 class),\n","               using softmax for multi-class probability output.\n","'''\n","#Step 5: Set Up the Pre-trained Model\n","#1. Resize the Images to 224x224\n","# Resize images before training\n","x_train_resized = tf.image.resize(x_train, (224, 224))\n","x_test_resized = tf.image.resize(x_test, (224, 224))\n","\n","# Check the shape to confirm resizing\n","print(f\"x_train_resized shape: {x_train_resized.shape}\")\n","print(f\"x_test_resized shape: {x_test_resized.shape}\")\n","\n"],"metadata":{"id":"XG_PrYy0ujCm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","Solution: Use Data Generators for On-the-Fly Resizing\n","Step-by-Step Implementation:\n","Use TensorFlow's ImageDataGenerator: This will resize images dynamically during training,\n","ensuring that only a batch of images is loaded into memory at a time, preventing crashes.\n","\n","'''\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Create a training ImageDataGenerator with data augmentation\n","train_datagen = ImageDataGenerator(\n","    rescale=1.0/255.0,         # Normalize pixel values to [0,1]\n","    rotation_range=15,        # Random rotation\n","    width_shift_range=0.1,    # Horizontal shift\n","    height_shift_range=0.1,   # Vertical shift\n","    horizontal_flip=True      # Randomly flip images horizontally\n",")\n","\n","# Create a validation ImageDataGenerator with only rescaling\n","test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n","\n","# Flow the training images from the array, with on-the-fly resizing to 224x224\n","train_generator = train_datagen.flow(x_train, y_train, batch_size=64, target_size=(224, 224))\n","\n","# Flow the test images from the array, with on-the-fly resizing to 224x224\n","test_generator = test_datagen.flow(x_test, y_test, batch_size=64, target_size=(224, 224))\n"],"metadata":{"id":"UXS_tAk5AMmu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","2.Set Up Your Model Using MobileNetV2: Now, use the pre-trained MobileNetV2 model with the appropriate input size:\n","'''\n","from tensorflow.keras.applications import MobileNetV2\n","from tensorflow.keras import layers, models\n","\n","# Initialize MobileNetV2 with pre-trained weights\n","base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","base_model.trainable = False\n","\n","# Build the full model\n","model = models.Sequential([\n","    base_model,\n","    layers.GlobalAveragePooling2D(),\n","    layers.Dense(1024, activation='relu'),\n","    layers.Dropout(0.5),\n","    layers.Dense(10, activation='softmax')\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# Show a summary of the model\n","model.summary()\n"],"metadata":{"id":"uWQCkVxNAmPL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"32T5jrERATK5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","#Step 5: Set Up the Pre-trained Model\n","#2. Modify the Model Setup\n","# Set up MobileNetV2 with the correct input shape\n","base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3)\n","\n","# Freeze the base model layers\n","base_model.trainable = False\n","\n","# Add custom layers on top of the base model\n","model = models.Sequential([\n","    base_model,\n","    layers.GlobalAveragePooling2D(),\n","    layers.Dense(1024, activation='relu'),\n","    layers.Dropout(0.5),\n","    layers.Dense(10, activation='softmax')\n","])\n","\n","# Show a summary of the model\n","model.summary()\n","'''"],"metadata":{"id":"hqGucTqC3v05"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Step 5: Set Up the Pre-trained Model\n","#3. Update Training Code\n","#Make sure to use the resized datasets (x_train_resized, x_test_resized) when training:\n","# Use data augmentation for training\n","batch_size = 64\n","epochs = 20\n","\n","history = model.fit(\n","    datagen.flow(x_train_resized, y_train, batch_size=batch_size),\n","    validation_data=(x_test_resized, y_test),\n","    steps_per_epoch=len(x_train) // batch_size,\n","    epochs=epochs\n",")\n","\n","'''\n","Explanation:\n","Image Resizing: By resizing the CIFAR-10 images to 224x224, you ensure that they match the input shape expected by MobileNetV2, allowing the pre-trained weights to load properly.\n","Model Adjustments: Using the appropriate input_shape argument and keeping weights='imagenet' will utilize the pre-trained feature extractor effectively.\n","This approach should help you avoid the shape mismatch errors and leverage the pre-trained model correctly.\n","'''"],"metadata":{"id":"qN0Rs-NL2si4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Step 6: Compile the Model\n","'''optimizer='adam': Efficient optimizer that adjusts the learning rate during training.\n","loss='categorical_crossentropy': Appropriate loss function for multi-class classification.\n","metrics=['accuracy']: Monitors the accuracy during training.\n","'''\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n"],"metadata":{"id":"XCsZGlUGujFe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Step 7: Train the Model\n","'''\n","Batch size: Number of images processed before updating the model's weights.\n","Epochs: One epoch means the model has seen the entire dataset once.\n","       More epochs allow the model to learn better.\n","datagen.flow: Uses augmented data during training.\n","validation_data: Evaluates the model's performance on unseen data.\n","'''\n","# Use data augmentation for training\n","batch_size = 64\n","epochs = 20\n","\n","model.fit(\n","    datagen.flow(x_train, y_train, batch_size=batch_size),\n","    validation_data=(x_test, y_test),\n","    steps_per_epoch=len(x_train) // batch_size,\n","    epochs=epochs\n",")\n"],"metadata":{"id":"x7eK31DcujJA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Step 8: Evaluate the Model\n","'''\n","Evaluation: After training, this step tests how well the model performs on the test dataset.\n","Test accuracy: A measure of how many images the model correctly classifies.\n","'''\n","test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n","print(f'Test Accuracy: {test_acc}')\n"],"metadata":{"id":"5TpDsOQYvGAw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Step 9: Fine-tune the Model (Optional)\n","'''\n","Fine-tuning: Unfreezes the base model layers to improve performance\n","             by adjusting the pre-trained weights slightly.\n","Using a lower learning rate ensures that changes are small and controlled.\n","'''\n","# Unfreeze some layers of the base model\n","base_model.trainable = True\n","\n","# Recompile the model with a lower learning rate\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Fine-tune the model\n","history_fine = model.fit(\n","    datagen.flow(x_train, y_train, batch_size=batch_size),\n","    validation_data=(x_test, y_test),\n","    steps_per_epoch=len(x_train) // batch_size,\n","    epochs=10\n",")\n"],"metadata":{"id":"WZ1jUjuLvGEZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Step 10: Save the Model\n","'''\n","Why save the model?\n","After training, you can save the model to use it later without retraining.\n","This .h5 file can be loaded and deployed anywhere.\n","'''\n","\n","model.save('cifar10_classifier.h5')\n"],"metadata":{"id":"LNxThYlUvGHw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#\n","#"],"metadata":{"id":"AXop-UdgvITX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#\n","#"],"metadata":{"id":"4Il1J5NRvIWl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#\n","#"],"metadata":{"id":"iOUoc8S9vIaA"},"execution_count":null,"outputs":[]}]}